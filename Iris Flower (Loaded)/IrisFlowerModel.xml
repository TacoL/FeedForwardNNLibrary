<?xml version="1.0" encoding="utf-8"?>
<network>
	<numInputs>4</numInputs>
	<learningRate>0.22</learningRate>
	<momentumScalar>0.12</momentumScalar>
	<batchSize>150</batchSize>
	<layers>
		<layer1>
			<ActivationFunction>Tanh</ActivationFunction>
			<neurons>
				<neuron0>
					<weights>
						<weight0>1.04549096707048</weight0>
						<weight1>1.51100906924024</weight1>
						<weight2>-2.8261876632663</weight2>
						<weight3>-2.16146792160002</weight3>
					</weights>
					<bias>1.64544079531626</bias>
				</neuron0>
				<neuron1>
					<weights>
						<weight0>-0.0633477710302642</weight0>
						<weight1>-0.707990894112059</weight1>
						<weight2>-0.460514237711342</weight2>
						<weight3>0.347707878554503</weight3>
					</weights>
					<bias>-0.339341310950213</bias>
				</neuron1>
				<neuron2>
					<weights>
						<weight0>0.999343843241509</weight0>
						<weight1>1.40981376127784</weight1>
						<weight2>-2.85094863938559</weight2>
						<weight3>-2.10119378542956</weight3>
					</weights>
					<bias>1.71677311606889</bias>
				</neuron2>
				<neuron3>
					<weights>
						<weight0>-0.201232547662166</weight0>
						<weight1>1.84257115821876</weight1>
						<weight2>-3.04399743599929</weight2>
						<weight3>-3.42296006933639</weight3>
					</weights>
					<bias>1.03535420392813</bias>
				</neuron3>
				<neuron4>
					<weights>
						<weight0>-0.398737600224637</weight0>
						<weight1>-1.36067172826425</weight1>
						<weight2>2.04144580138603</weight2>
						<weight3>2.17179954137579</weight3>
					</weights>
					<bias>-1.70444387875068</bias>
				</neuron4>
				<neuron5>
					<weights>
						<weight0>0.229785660835435</weight0>
						<weight1>0.269322566525744</weight1>
						<weight2>-0.541803122803869</weight2>
						<weight3>-1.22257309812068</weight3>
					</weights>
					<bias>0.369329022755549</bias>
				</neuron5>
				<neuron6>
					<weights>
						<weight0>-0.45337884406561</weight0>
						<weight1>-0.478366122273093</weight1>
						<weight2>-0.289901400431105</weight2>
						<weight3>-0.309776477091007</weight3>
					</weights>
					<bias>-0.0884373934520878</bias>
				</neuron6>
				<neuron7>
					<weights>
						<weight0>-0.202415536854291</weight0>
						<weight1>-1.14180768402873</weight1>
						<weight2>0.230602972097896</weight2>
						<weight3>-0.098665721344425</weight3>
					</weights>
					<bias>-0.239071371585308</bias>
				</neuron7>
			</neurons>
		</layer1>
		<layer2>
			<ActivationFunction>Softmax</ActivationFunction>
			<neurons>
				<neuron0>
					<weights>
						<weight0>0.514398092166244</weight0>
						<weight1>0.103027916409772</weight1>
						<weight2>1.13555871061995</weight2>
						<weight3>1.800471768575</weight3>
						<weight4>-0.514259354314912</weight4>
						<weight5>0.930419939689693</weight5>
						<weight6>0.391437425876408</weight6>
						<weight7>-0.359012131238849</weight7>
					</weights>
					<bias>-0.714230954006432</bias>
				</neuron0>
				<neuron1>
					<weights>
						<weight0>1.69021239142022</weight0>
						<weight1>0.882716328754704</weight1>
						<weight2>1.54156704351427</weight2>
						<weight3>-4.76927463043784</weight3>
						<weight4>-1.38026444061999</weight4>
						<weight5>0.054580848432314</weight5>
						<weight6>0.635489636139582</weight6>
						<weight7>1.1985352854028</weight7>
					</weights>
					<bias>-1.06297962367424</bias>
				</neuron1>
				<neuron2>
					<weights>
						<weight0>-3.58337349698893</weight0>
						<weight1>0.141329015239641</weight1>
						<weight2>-3.68331468321465</weight2>
						<weight3>-1.49761812028677</weight3>
						<weight4>2.96244943533234</weight4>
						<weight5>-1.28827988885883</weight5>
						<weight6>-0.366585583147299</weight6>
						<weight7>0.479587962662654</weight7>
					</weights>
					<bias>-0.972073996806109</bias>
				</neuron2>
			</neurons>
		</layer2>
	</layers>
</network>